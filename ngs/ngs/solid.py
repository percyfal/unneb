import os
import sys
import glob
from string import Template
__version__ = '0.2'

TEMPLATEDIR= os.path.join(os.path.dirname(__file__), "solid_templates")

# Templates
ini_templates = {
    'global_ini' : r"""
##  global parameters
run.name = %s
sample.name = %s

base.dir=../../
output.dir = ${base.dir}/output
temp.dir = ${base.dir}/temp
intermediate.dir = ${base.dir}/intermediate
log.dir = ${base.dir}/log
reads.result.dir = ${base.dir}/reads
reference=%s
scratch.dir=/scratch/solid

# override it locally in the pipeline ini file when needed
primer.set = %s

pipeline.cleanup.middle.files = 1
pipeline.cleanup.temp.files=1
job.cleanup.temp.files = 1
""",
    'mapping_ini' : r"""##  global settings for the pipeline run
import %s
read.length = %i

##  mapping pipeline
# mandatory parameters
# --------------------
mapping.run = 1
mapping.tagfiles.dir = %s
#mapping.tagfiles=
mapping.output.dir = %s

# optional parameters
# -------------------
# Parameter specifies the subfolder where repetitive .ma and .csfasta files were written
#mapping.repetitive.dir=
#mapping.number.of.nodes=3
#read.length=25
#mismatch.level=6
# Parameter defines the maximum number of best hits found in mapping.  [100]
matching.max.hits=10
#mask.positions=
#mapping.schema.file=
#matching.use.iub.reference=0
#mapping.run.classic=0
# Parameter specifies a list of anchorLength.mismatchAllowed.anchorStart separated by comma for unmapped reads.
#mapping.scheme.unmapped=
#mapping.scheme.unmapped.25=25.2.0
#mapping.scheme.repetitive.25=
#mapping.scheme.unmapped.35=30.3.0
#mapping.scheme.repetitive.35=
# Parameter specifies a list of anchorLength.mismatchAllowed.anchorStart separated by comma for unmapped reads of length greater or equal to 50.
#mapping.scheme.unmapped.50=25.2.0,25.2.15
# Parameter specifies an estimate of the sequencing error rate.
# Default value when not specified is 0.2
#mapping.qual.error.rate=

# Cleaning files 0/1 - files have to be removed when rerunning for some reason
#pipeline.cleanup.middle.files = 1
#job.cleanup.temp.files = 1

# Parameter scpecifies the threshold to decide whether a read is mapped uniquely in the reference.
#clear.zone=5

# Parameter specifies a negative score for mismatch which is used in local alignment mode.  
# When this is set to a non-negative number, the local mode is turned off and the output format of hits remains the same as that in V3.
# Default value when not specified is -2.0
#mapping.mismatch.penalty=

# Parameter specifies the full path and file name of the mapping stats file generated by the plugin
# Default value when not specified is ${output.dir}/s_mapping/mapping-stats.txt
mapping.stats.output.file=%s/mapping-stats.txt
""",
    'saet_ini' : r"""

""",
    'matobam_ini' : r"""############################
##
## matobam ini template
##
##############################
import %s
# Parameter specifies whether to run maToBam plugin. [1 - run, 0 - do not run]
ma.to.bam.run = 1
ma.to.bam.output.dir = ${output.dir}/bam
ma.to.bam.temp.dir = ${output.dir}/temp
ma.to.bam.qual.file = %s
ma.to.bam.match.file = %s
ma.to.bam.reference = %s
ma.to.bam.distribute.number.of.workers = 11
ma.to.bam.output.filter=primary
ma.to.bam.correct.to=reference
ma.to.bam.clear.zone=5
ma.to.bam.mismatch.penalty=-2.0
ma.to.bam.iubs.to=missing
ma.to.bam.library.type=fragment
ma.to.bam.library.name=%s
#ma.to.bam.slide.name=
#ma.to.bam.description=
ma.to.bam.sequencing.center=SciLife
ma.to.bam.tints=agy
ma.to.bam.base.qv.max=40
#ma.to.bam.temporary.dir=
""",

    'dibayes_ini' : r"""
## This is a configuration file for diBayes.
import %s
## ********************************************
## mapping parameters
## ********************************************
mapping.output.dir=${output.dir}/${primer.set}_mapping
## ********************************************
## positionErrors parameters
## ********************************************
position.errors.output.dir=${output.dir}/positionErrors/
## ********************************************
## diBayes parameters
## ********************************************
# mandatory parameters
# --------------------
# Parameter to specify whether to run Mutation Pipeline.
# [Options: 1 - Run, 0 - Don't run].
dibayes.run=1
# Parameter specifies the full path to location of directory
# where to write diBayes output files.
dibayes.output.dir=${output.dir}/diBayes/DB_OUT
# Parameter specifies the full path to location of directory in
# which to place temporary working files
dibayes.working.dir = ${temp.dir}/dibayes
# Parameter specifies the full path to the log directory
dibayes.log.dir = ${log.dir}/dibayes
# Parameter specifies the name of subdirectory in the output
# folder and the Name of the experimentprefix of the output files
dibayes.output.prefix = test_SNP
# Parameter specifies the reference sequence fasta file with full path
reference=%s
# Parameters specifies colon-separated list of the input sets in the format:
# file-full-path:mate-pair-flag:f3-position-err-file:[r3-position-err-file]
input.file.info=%s
# Maximal read length (e.g. 50). Note: this program allows
# combining reads from sources with different read lengths.
maximal.read.length = %s
# The parameter the criteria to report SNPs. [Options:highest|high|medium|low]
# Default value is 'medium' when not mentioned.
call.stringency = high
# optional parameters
# Changes on the algorithm fine tuning parameters will overridethe values that are preset by call.stringency setting.
# -------------------
# Polymorphism rate: Expected frequency of heterozygotes in the population: for example, 0.001 in humans
poly.rate = 0.001
# Parameter specifies to detect 2 Adjacent SNP's. [Options: 0 - do not detect, 1 - detect].
#detect.2.adjacent.snps=0
# Parameter specifies whether to write fasta file or not. [Options: 0 - Don't write fasta file, 1 - Write fasta file].
# Default value when not specified is 1.
write.fasta = 1
# Parameter specifies whether to write consensus_calls.txt. [Options: 0 - Don't write, 1 - Write].
# Default value when not specified is 1.
write.consensus = 1
# Parameter specifies whether to compress consensus_calls.txt by zipping it. [Options: 0 - Don't ZIP, 1 - ZIP].
compress.consensus = 0
# Parameter specifies whether to clean up the temporary files. [Options: 0 - Don.t clean, 1- Clean].
# Default value when not specified is 1.
#cleanup.tmp.files =1
# Parameter specifies not to call SNPs when the coverage of position is too high comparing to the median of the coverage distribution of all positions.
# NOTE: enable this filter for whole genome re-sequencing application; disable (default) it for transcriptome or target re-sequencing.
het.skip.high.coverage=0
# Parameter specifies the minimum mapping/pairing quality value.
# Default value when not specified is 0
#reads.min.mapping.qv=8
# Parameter specifies the required minimum for color quality value of non-reference allele to call a heterozygous SNP.
#het.min.nonref.color.qv=7
# Parameter specifies the required minimum for color quality value of non-reference allele to call a homozygous SNP.
#hom.min.nonref.color.qv=7
# Parameter species the requirement that the novel allele be on both strands :
# Parameter specifies the requirement that the novel allele is present on both strands and
# statistically similarly represented on both strand for both heterozygous and homozygous positionsSNPs.
# [Options: 0 - don't require, 1 - require]
#snp.both.strands = 0
# Parameter specifies the minimum required coverage to call a heterozygous SNP.
# [Allowed Values: Integer, 1-n]
#het.min.coverage = 3
# Parameter specifies Mthe minimum number of unique start position required to call a heterozgyote.
# [Allowed values: Integer, 1-n]
#het.min.start.pos = 3
# Parameter specifies the proportion of the reads containing either of the two candidate alleles.
# Filters positions with high raw error rate.
# [Allowed values: Float, 0-1]
#het.min.ratio.validreads=0.65
# The less common allele must be at least this proportion of the reads of the two heterozygote alleles.heterozygote.
# [Allowed values: Float, 0-1]
#het.min.allele.ratio=0.15
# Parameter specifies the Require at minimumleast 2 number of reads of an apparently valid tricolor calls to pass through filter to call 2 adjacent basesSNPs. i
# [Allowed Values: Integer]
#het.min.counts.tricolor=2
# Parameter specifies the required minimum coverage to call a homozygous SNP.
#hom.min.coverage=3
# Parameter specifies the Mminimum number of unique start position required to call a homozgyote.
# [Allowed values: Integer, 1-n]
#hom.min.start.pos=3
# Parameter specifies the required minimum coverage of candidate allele to consider this genome position for a Hhomozygous call.
#hom.min.allele.count=3
# Parameter specifies whether or not to filter the reads with indels.[Options: 0 - don't filter, 1 - filter].
# Default value when not specified is 1
#reads.no.indel=1
# Parameter specifies whether or not the reads to be are uniquely mapped. [Options: 0 - don't require, 1 - require].
# Default value when not specified is 0
#reads.only.unique=0
# Parameter specifies the threshold of mismatch/alignment length ratio.
# The reads whose mismatch/alignment length ratio is HIGHER than this specified threshold will be filtered.
# [Allowed values: Float, 0 - 1, 1 - don't filer]
#reads.max.mismatch.alignlength.ratio=1.0
# Parameter specifies rtTthe threshold of alignment-length / read-length ratio.
# The reads whose alignment-length/read-length ratio is are LESS than this specified threshold will be filtered.
# [Allowed values: Float, 0 - 1, 0 - don't filer]
#reads.min.mismatch.alignlength.ratio=0.0
# Parameter specifies whether to include the reads that only have one tag mapped (their mate tags are either unmapped or missing.)
# [Options: 0 - don't include, 1 - include]
#reads.include.no.mate=0

# Annotation pipeline
annotation.human.hg18=0
#annotation.gtf.file
#annotation.dbsnp.file.snpchrpos=
#annotation.dbsnp.file.snpcontigloc=
#annotation.dbsnp.file.snpcontiglocusid=

""",

    'positionError_ini' : r"""##  global parameters
import %s

##      position errors pipeline
position.errors.run = 1

# Location of BAM file from pairing plugin
# pairing.bam.dir=${output.dir}/pairing/

# Name of the BAM file for which position errors are to be calculated. If this key is missing a wild card search will be used. 
# If there is more than one .gff3 file in the input directory a position errors file will be generated for each one. (Optional)
# position.errors.input.bam.file = ${output.dir}/pairing/${primer.set.1}-${primer.set.2}-Paired.bam

# Position error output directory
position.errors.output.dir=${output.dir}/positionErrors

# Position error output file name
# position.errors.file=
"""
    }

# Utility functions, not for export
def _make_dirs(d):
    for k in d.keys():
        if not os.path.exists(d[k]):
            os.makedirs(d[k])

def _write_template(fo, tmpl, write=True):
    """Write the template"""
    print "Writing template " + fo
    if write:
        if not os.path.exists(fo):
            fp = open(fo, "w")
            fp.write(tmpl)
            fp.close()
        return 
    else:
        return tmpl
    
class PrimerSet():
    """Holds information about a primer set"""
    def __init__(self, primer, readlength, project):
        # Primer is one of F3, R3, F5-P2, F5-BC
        self.primer = primer
        self.read_length = readlength
        self.workdir = os.path.join(project.workdir,  primer + "_mapping")
        self.outputdir = os.path.join(project.outputdir, primer + "_mapping")
        self.reads = os.path.join(project.reads,  primer)
        self.project = project
        self._makedirs()

    def _makedirs(self):
        _make_dir(self.workdir)
        _make_dir(self.outputdir)
        _make_dir(self.reads)

    def mapping_ini_template(self, write=True):
        """mapping.ini template"""
        template = ini_templates['mapping_ini'] % ("../globals/" + self.project.global_ini, self.read_length, self.reads, self.outputdir, self.outputdir)
        if write:
            _write_template(os.path.join(self.workdir, "mapping.ini"), template)
        return template

    def matobam_ini_template(self, write=True):
        """matobam.ini template"""
        if len(glob.glob(os.path.join(self.reads, "*.qual"))) > 0:
            qualfile = glob.glob(os.path.join(self.reads, "*.qual"))[0]
        else:
            sys.stderr.write("\nWARNING: No quality file found\n")
            qualfile = ""
        matchfile = os.path.join(self.outputdir, self.project.sample + "_" + self.primer + ".csfasta.ma")
        template = ini_templates['matobam_ini'] % ("../globals/" + self.project.global_ini, qualfile, matchfile, self.project.reference, self.project.sample)
        if write:
            _write_template(os.path.join(self.workdir, "matobam.ini"), template)
        return template

    def saet_ini_template(self, write=True):
        """saet.ini template"""
        template = ini_templates['saet_ini'] % ()
        if write:
            _write_template(os.path.join(self.workdir, "saet.ini"), template)
        return template
    
    def bam_file(self):
        """get bam file name for this primer set"""
        return os.path.join(self.project.outputdir, "bam", self.project.sample + "_" + self.primer + ".csfasta.ma" + ".bam")

    def __str__(self):
        s = "\n".join(["\t".join(["Primer:",  self.primer]),
                       "\t".join(["Workdir:",  self.workdir]),
                       "\t".join(["Outputdir:",  self.outputdir]), 
                       "\t".join(["Reads:",  self.reads]),
                       "\t".join(["Basedir:",  self.project.basedir])])
        return s

class SolidProject():
    """Generate templates for SOLiD projects"""
    def __init__(self, runname, sample, reference, basedir="./"):
        self.runname = runname
        self.sample = sample
        self.reference = reference
        self.basedir = basedir
        self.global_ini = "globals.ini"
        self.workdir = os.path.join(basedir, "workdir")
        self.outputdir = os.path.join(basedir, "output")
        self.reads = os.path.join(basedir, "reads")
        self.logdir = os.path.join(basedir, "log")
        self.tempdir = os.path.join(basedir, "temp")
        self.intermediatedir = os.path.join(basedir, "intermediate")
        self.globaldir = os.path.join(basedir, "workdir", "globals")
        self.dibayesdir = os.path.join(basedir, "workdir", "dibayes")
        self.positionerrordir = os.path.join(basedir, "workdir", "positionErrors")
        self.dibayesoutputdir = os.path.join(basedir, "output", "dibayes")
        self.positionerroroutputdir = os.path.join(basedir, "output", "positionErrors")
        self.primersets = {}

        _make_dir(self.logdir)
        _make_dir(self.tempdir)
        _make_dir(self.intermediatedir)

    def add_primer_set(self, primer, readlength=50):
        self.primersets[primer] = PrimerSet(primer, readlength, self)
        self.primersets[primer].mapping_ini_template()
        self.primersets[primer].matobam_ini_template()
            
    def max_read_length(self):
        rl = 0
        for k in self.primersets.keys():
            if self.primersets[k].read_length > rl:
                rl = self.primersets[k].read_length
        return rl
    
    def bamfiles(self):
        bf = []
        for k in self.primersets.keys():
            bf.append(self.primersets[k].bam_file())
        return bf

    def mapping_plan(self):
        """Make a mapping plan file"""
        pass

    def global_ini_template(self, write=True):
        """global.ini template"""
        _make_dir(self.globaldir)
        template = ini_templates['global_ini'] % (self.runname, self.sample,  self.reference, ",".join(self.primersets.keys()))
        if write:
            _write_template(os.path.join(self.globaldir, "globals.ini"), template)
        return template

    def dibayes_ini_template(self, run_type = 0, write=True):
        """dibayes.ini template"""
        _make_dir(self.dibayesdir)
        _make_dir(self.dibayesoutputdir)
        self.positionerror_ini_template()
        template = ini_templates['dibayes_ini'] % ("../globals/" + self.global_ini, self.reference, self.outputdir + ":" + str(run_type) + ":" + self.positionerroroutputdir,  self.max_read_length())
        if write:
            _write_template(os.path.join(self.dibayesdir, "dibayes.ini"), template)
        return template

    def positionerror_ini_template(self, write=True):
        """positionError.ini template"""
        _make_dir(self.positionerrordir)
        _make_dir(self.positionerroroutputdir)
        template = ini_templates['positionError_ini'] % ("../globals/" + self.global_ini)
        if write:
            _write_template(os.path.join(self.positionerrordir, "positionerror.ini"), template)
        return template
        


class SOLiDProject(object):
    """Template class for SOLiD projects"""
    _key_map = {}
    def __init__(self, runname, samplename, reference, basedir):
        self.config = {} # For keys that can be None
        self.workflow = self.__class__.__name__
        self.basedirs = {'base' : basedir,
                         'work': os.path.join(basedir, "workdir"),
                         'output' : os.path.join(basedir, "output"),
                         'reads' : os.path.join(basedir, "reads"),
                         'log' : os.path.join(basedir, "log"),
                         'temp' : os.path.join(basedir, "temp"),
                         'intermediate' : os.path.join(basedir, "intermediate")
                         }
        # self.workdirs = {'dibayes' : os.path.join(basedir, "workdir", "dibayes"),
        #                  'positionErrors' : os.path.join(basedir, "workdir", "positionErrors")
        #                  }
        # self.outdirs = {'dibayes' : os.path.join(basedir, "output", "dibayes"),
        #                 'positionErrors' : os.path.join(basedir, "output", "positionErrors")
        #                 }
        self.template_path = os.path.join(TEMPLATEDIR, self.workflow)
        self.primersets = {}
        self.d = {'runname' :runname,
                  'samplename' : samplename,
                  'reference' : reference,
                  'basedir' : basedir,
                  'global_ini' : os.path.join(basedir, "workdir", "globals", "global.ini")
                  }
        _make_dirs(self.basedirs)
        
    def _set_d(self):
        d = {}
        for k in self.config.keys():
            d[k] = " = ".join([self._key_map[k], str(self.config[k])])
            if self.config[k] == None:
                d[k] = "# " + d[k]
        return d

    def ini_file(self, filename):
        inifile = os.path.join(self.template_path, filename)
        with open(inifile) as in_handle:
            tmpl = Template(in_handle.read())
        return tmpl.safe_substitute(self.d)

    def global_ini(self):
        return self.ini_file('global.ini')

class WT_SingleRead(SOLiDProject):
    def __init__(self, runname, samplename, reference, basedir, csfastafile, qualfile, filterref, exons_gtf, junction_ref, read_length=50):
        SOLiDProject.__init__(self, runname, samplename, reference, basedir)
        self.d.update({
                'read_length':read_length,
                'csfastafile':csfastafile,
                'qualfile':qualfile, 
                'filter_reference':filterref,
                'exons_gtf':exons_gtf,
                'junction_reference':junction_ref
                })

    def wt_single_read_ini(self):
        return self.ini_file('wt.single.read.workflow.ini')

class TargetedFrag(SOLiDProject):
    def __init__(self, runname, samplename, reference, basedir, targetfile, annotation_gtf_file=None, cmap = None, read_length=50, annotation_human_hg18=0):
        SOLiDProject.__init__(self, runname, samplename, reference, basedir)
        _key_map = self._key_map.update({'cmap':'cmap', 'annotation_gtf_file':'annotation.gtf.file'})
        self.config.update({
                'cmap' : cmap,
                'annotation_gtf_file':annotation_gtf_file
                })
        self.d.update( {
                        'target_file' : targetfile,
                        'annotation_human_hg18' : annotation_human_hg18
                        } )
        self._set_d()
        self.primersets['F3'] = Primer("F3", read_length, self)
        
    def init_project(self, saet=True, small_indel_frag=True, enrichment=True, targeted_workflow=True):
        analysis_plan = os.path.join(self.basedirs['base'], 'analysis.plan')
        ap = []
        if saet:
            self.primersets['F3'].saet_ini()
            ap.append(os.path.join(self.primersets['F3'].dirs['work'], 'saet.ini'))
        if small_indel_frag:
            self.primersets['F3'].enrichment_ini()
            ap.append(os.path.join(self.primersets['F3'].dirs['work'], 'small.indel.frag.ini'))
        if enrichment:
            self.primersets['F3'].targeted_frag_workflow_ini()
            ap.append(os.path.join(self.primersets['F3'].dirs['work'], 'enrichment.ini'))
        if targeted_workflow:
            self.primersets['F3'].small_indel_frag_ini()
            ap.append(os.path.join(self.primersets['F3'].dirs['work'], 'targeted.frag.workflow.ini'))
        with open(analysis_plan, 'w') as apf:
            apf.write("\n".join(ap))
                          

class Primer(object):
    """Class for primer set"""
    def __init__(self, primer, readlength, project):
        self.project = project
        self.dirs = {'work': os.path.join(self.project.basedirs['work'],  primer + "_mapping"),
                     'output':os.path.join(self.project.basedirs['output'], primer + "_mapping"),
                     'reads':os.path.join(self.project.basedirs['reads'],  primer)
                     }
        _make_dirs(self.dirs)
        self.d = {'primer': primer,
                  'read_length':readlength,
                  'csfastafilebase' : self.project.d['samplename'] + "_" + primer + ".csfasta",
                  'saet_input_csfastafile' : os.path.join(self.dirs['reads'], self.project.d['samplename'] + "_" + primer + ".csfasta"),
                  'saet_input_qualfile' : os.path.join(self.dirs['reads'], self.project.d['samplename'] + "_" + primer + "_QV.qual"),
                  'matobamqual' : self.project.d['samplename'] + "_" + primer + "_QV.qual" 
                  # As of yet I have no idea what this looks like
                  # 'small_indel_frag_qual' : self.project
                  }


    def saet_ini(self, write=True):
        tmpl = self.ini_file('saet.ini')
        return _write_template(os.path.join(self.dirs['work'], 'saet.ini'), tmpl, write)

    def enrichment_ini(self, write=True):
        tmpl = self.ini_file('enrichment.ini')
        return _write_template(os.path.join(self.dirs['work'], 'enrichment.ini'), tmpl, write)

    def targeted_frag_workflow_ini(self, write=True):
        tmpl = self.ini_file('targeted.frag.workflow.ini')
        return _write_template(os.path.join(self.dirs['work'], 'targeted.frag.workflow.ini'), tmpl, write)

    def small_indel_frag_ini(self, write=True):
        tmpl = self.ini_file('small.indel.frag.ini')
        return _write_template(self.dirs['work'], tmpl, write)
    
    def ini_file(self, filename):
        inifile = os.path.join(self.project.template_path, filename)
        with open(inifile) as in_handle:
            tmpl = Template(in_handle.read())
        # Global project dictionary
        d = self.project.d
        # Primer specific dictionary
        d.update(self.d)
        print "Template dir " +  str(dir(tmpl))
        return tmpl.safe_substitute(d)



class TargetedPE(SOLiDProject):
    def __init__(self):
        pass

class ReseqFrag(SOLiDProject):
    def __init__(self):
        pass



